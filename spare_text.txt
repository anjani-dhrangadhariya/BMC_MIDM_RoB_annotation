Discussion section - LLM evaluation
Subsection - LLM evaluation


% -------------- Additional --------------
%In cases where no information was found to answer a SQ, ChatPDF generated a response by itself giving example sentences that could be used to answer that question.
%Can retrieve multiple related answers for a RoB question prompt and one of that has to be the correct answer and should be the same as what the annotators annotated.
%After instructing ChatPDF to look into the uploaded PDF and not generate sentences by itself, it gives the following output. (this was the unpaid version of ChatPDF)
%``I apologize, but as an AI language model, I do not have access to any uploaded PDFs or any external sources. Please provide me with the PDF you are referring to, and I will be happy to extract the sentences related to answering the signalling question RoB 1.1.'' (this was the unpaid version of ChatPDF)

%TODO: Discuss how the prompt was set to only extract the sentences from the uploaded PDF.
%In our initial experiments, we had a few examples where ChatPDF generated an answer to the signalling question, but these sentences comprising the answer were not to be found in the input PDF document.
%In one particular instance, LLM answered correctly saying that the sequence was randomly generated and also extracted the sentence related to answering the question, but the generated sentence was not found in the PDF.
%These are likely the cases of hallucination.
%In such cases, the PDF was reloaded into ChatPDF and the re-prompted for that particular signalling question.


Subsection - Conflict Resolution
% Discuss the kind of conflict identified in the doubly-annotated documents.
% How were these conflicts resolved?
%During conflict resolution, we found that certain instances where both annotators marked the same text evidence to answer the same SQ but gave different judgment responses.
%We resorted to face-to-face conflict resolution in this case for every conflict case and updated the visual placards.
%We went for conflict resolution in the scenarios when
%1) the annotators marked different parts of text to answer the same question with same judgment. (\url{https://docs.google.com/spreadsheets/d/14jYqXTcnVzZsC5pbKQ2GcwtVrwl81DG9Yo5uhCJZzjo/edit#gid=1107412538})
%2) the annotators marked same part of text to answer the same question, but gave different judgment option for it. (\url{https://docs.google.com/spreadsheets/d/14jYqXTcnVzZsC5pbKQ2GcwtVrwl81DG9Yo5uhCJZzjo/edit#gid=0})
%Both annotators use different parts of text to answer the same signalling question, but give different judgment options. \url{https://docs.google.com/spreadsheets/d/14jYqXTcnVzZsC5pbKQ2GcwtVrwl81DG9Yo5uhCJZzjo/edit#gid=1107412538}
%In case, one annotator selected a part of text and another the same text but an additional text too, then we will select the annotations from the longer annotation.